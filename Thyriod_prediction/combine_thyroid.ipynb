{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('Combined_Thyroid.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4201 entries, 0 to 4200\n",
      "Data columns (total 22 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   Age                      4201 non-null   int64  \n",
      " 1   Sex                      4201 non-null   int64  \n",
      " 2   On_thyroxine             4201 non-null   int64  \n",
      " 3   Query_on_thyroxine       4201 non-null   int64  \n",
      " 4   On_antithyroid_medicine  4201 non-null   int64  \n",
      " 5   Sick                     4201 non-null   int64  \n",
      " 6   Pregnant                 4201 non-null   int64  \n",
      " 7   Thyroid_surgery          4201 non-null   int64  \n",
      " 8   I131_treatment           4201 non-null   int64  \n",
      " 9   Query_hypothyroid        4201 non-null   int64  \n",
      " 10  Query_hyperthyroid       4201 non-null   int64  \n",
      " 11  Lithium                  4201 non-null   int64  \n",
      " 12  Goitre                   4201 non-null   int64  \n",
      " 13  Tumor                    4201 non-null   int64  \n",
      " 14  Hypopituitary            4201 non-null   int64  \n",
      " 15  Pysch                    4201 non-null   int64  \n",
      " 16  TSH                      4201 non-null   float64\n",
      " 17  T3                       4201 non-null   float64\n",
      " 18  TT4                      4201 non-null   float64\n",
      " 19  T4U                      4201 non-null   float64\n",
      " 20  FTI                      4201 non-null   float64\n",
      " 21  Class                    4201 non-null   int64  \n",
      "dtypes: float64(5), int64(17)\n",
      "memory usage: 722.2 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>On_thyroxine</th>\n",
       "      <th>Query_on_thyroxine</th>\n",
       "      <th>On_antithyroid_medicine</th>\n",
       "      <th>Sick</th>\n",
       "      <th>Pregnant</th>\n",
       "      <th>Thyroid_surgery</th>\n",
       "      <th>I131_treatment</th>\n",
       "      <th>Query_hypothyroid</th>\n",
       "      <th>...</th>\n",
       "      <th>Goitre</th>\n",
       "      <th>Tumor</th>\n",
       "      <th>Hypopituitary</th>\n",
       "      <th>Pysch</th>\n",
       "      <th>TSH</th>\n",
       "      <th>T3</th>\n",
       "      <th>TT4</th>\n",
       "      <th>T4U</th>\n",
       "      <th>FTI</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0520</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.0580</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Sex  On_thyroxine  Query_on_thyroxine  On_antithyroid_medicine  Sick  \\\n",
       "0    5    0             1                   0                        0     0   \n",
       "1   78    0             0                   0                        0     0   \n",
       "2   73    0             0                   0                        0     0   \n",
       "3   43    0             0                   0                        0     0   \n",
       "4   42    0             0                   0                        0     0   \n",
       "\n",
       "   Pregnant  Thyroid_surgery  I131_treatment  Query_hypothyroid  ...  Goitre  \\\n",
       "0         0                0               1                  0  ...       0   \n",
       "1         0                0               0                  1  ...       0   \n",
       "2         0                0               0                  0  ...       0   \n",
       "3         0                0               0                  0  ...       0   \n",
       "4         0                0               0                  0  ...       0   \n",
       "\n",
       "   Tumor  Hypopituitary  Pysch    TSH      T3     TT4    T4U     FTI  Class  \n",
       "0      0              0      0  0.061  0.0096  0.0130  0.116  0.0110      1  \n",
       "1      0              0      0  0.025  0.0090  0.0500  0.084  0.0600      1  \n",
       "2      0              0      0  0.047  0.0110  0.0520  0.090  0.0580      1  \n",
       "3      0              0      0  0.070  0.0050  0.0029  0.104  0.0028      1  \n",
       "4      0              0      0  0.031  0.0080  0.0130  0.119  0.0110      1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                        0\n",
       "Sex                        0\n",
       "On_thyroxine               0\n",
       "Query_on_thyroxine         0\n",
       "On_antithyroid_medicine    0\n",
       "Sick                       0\n",
       "Pregnant                   0\n",
       "Thyroid_surgery            0\n",
       "I131_treatment             0\n",
       "Query_hypothyroid          0\n",
       "Query_hyperthyroid         0\n",
       "Lithium                    0\n",
       "Goitre                     0\n",
       "Tumor                      0\n",
       "Hypopituitary              0\n",
       "Pysch                      0\n",
       "TSH                        0\n",
       "T3                         0\n",
       "TT4                        0\n",
       "T4U                        0\n",
       "FTI                        0\n",
       "Class                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Age',\n",
       " 'Sex',\n",
       " 'On_thyroxine',\n",
       " 'Query_on_thyroxine',\n",
       " 'On_antithyroid_medicine',\n",
       " 'Sick',\n",
       " 'Pregnant',\n",
       " 'Thyroid_surgery',\n",
       " 'I131_treatment',\n",
       " 'Query_hypothyroid',\n",
       " 'Query_hyperthyroid',\n",
       " 'Lithium',\n",
       " 'Goitre',\n",
       " 'Tumor',\n",
       " 'Hypopituitary',\n",
       " 'Pysch',\n",
       " 'TSH',\n",
       " 'T3',\n",
       " 'TT4',\n",
       " 'T4U',\n",
       " 'FTI',\n",
       " 'Class']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = df[['Age',\n",
    " 'Sex',\n",
    " 'On_thyroxine',\n",
    " 'Query_on_thyroxine',\n",
    " 'On_antithyroid_medicine',\n",
    " 'Sick',\n",
    " 'Pregnant',\n",
    " 'Thyroid_surgery',\n",
    " 'I131_treatment',\n",
    " 'Query_hypothyroid',\n",
    " 'Query_hyperthyroid',\n",
    " 'Lithium',\n",
    " 'Goitre',\n",
    " 'Tumor',\n",
    " 'Hypopituitary',\n",
    " 'Pysch',\n",
    " 'TSH',\n",
    " 'T3',\n",
    " 'TT4',\n",
    " 'T4U',\n",
    " 'FTI']].values\n",
    "Y1 = df['Class'].values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pass 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partition 1:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98        59\n",
      "           1       1.00      1.00      1.00       684\n",
      "           2       0.94      1.00      0.97        16\n",
      "           3       1.00      0.99      0.99        82\n",
      "\n",
      "    accuracy                           1.00       841\n",
      "   macro avg       0.97      1.00      0.98       841\n",
      "weighted avg       1.00      1.00      1.00       841\n",
      "\n",
      "-------------------------\n",
      "Partition 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97        57\n",
      "           1       1.00      1.00      1.00       705\n",
      "           2       0.64      1.00      0.78         7\n",
      "           3       1.00      0.94      0.97        71\n",
      "\n",
      "    accuracy                           0.99       840\n",
      "   macro avg       0.90      0.98      0.93       840\n",
      "weighted avg       0.99      0.99      0.99       840\n",
      "\n",
      "-------------------------\n",
      "Partition 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        54\n",
      "           1       1.00      1.00      1.00       722\n",
      "           2       0.78      1.00      0.88         7\n",
      "           3       1.00      0.96      0.98        57\n",
      "\n",
      "    accuracy                           1.00       840\n",
      "   macro avg       0.94      0.99      0.96       840\n",
      "weighted avg       1.00      1.00      1.00       840\n",
      "\n",
      "-------------------------\n",
      "Partition 4:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98        65\n",
      "           1       1.00      1.00      1.00       682\n",
      "           2       0.92      1.00      0.96        12\n",
      "           3       1.00      1.00      1.00        81\n",
      "\n",
      "    accuracy                           1.00       840\n",
      "   macro avg       0.98      0.99      0.99       840\n",
      "weighted avg       1.00      1.00      1.00       840\n",
      "\n",
      "-------------------------\n",
      "Partition 5:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        56\n",
      "           1       1.00      1.00      1.00       716\n",
      "           2       0.90      1.00      0.95         9\n",
      "           3       1.00      0.98      0.99        59\n",
      "\n",
      "    accuracy                           1.00       840\n",
      "   macro avg       0.97      0.99      0.98       840\n",
      "weighted avg       1.00      1.00      1.00       840\n",
      "\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "X = np.array(X1)  # input features\n",
    "y = np.array(Y1)  # output labels\n",
    "\n",
    "# Define the number of partitions\n",
    "n_splits = 5\n",
    "\n",
    "# Shuffle the data randomly\n",
    "np.random.seed(42)\n",
    "indices = np.random.permutation(len(X))\n",
    "X = X[indices]\n",
    "y = y[indices]\n",
    "\n",
    "# Create the KFold object to generate the partitions\n",
    "kf = KFold(n_splits=n_splits)\n",
    "\n",
    "# Train and test the random forest model on each partition\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    print(f\"Partition {i+1}:\")\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Train the random forest model on the training set\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Test the random forest model on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    predicted_integers = [int(round(value)) for value in y_pred]\n",
    "\n",
    "    print(classification_report(y_test,predicted_integers))\n",
    "\n",
    "    \n",
    "    print('-'*25)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pass 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partition 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        57\n",
      "           1       1.00      1.00      1.00       705\n",
      "           2       1.00      1.00      1.00         7\n",
      "           3       1.00      1.00      1.00        71\n",
      "\n",
      "    accuracy                           1.00       840\n",
      "   macro avg       1.00      1.00      1.00       840\n",
      "weighted avg       1.00      1.00      1.00       840\n",
      "\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        54\n",
      "           1       1.00      1.00      1.00       722\n",
      "           2       1.00      1.00      1.00         7\n",
      "           3       1.00      1.00      1.00        57\n",
      "\n",
      "    accuracy                           1.00       840\n",
      "   macro avg       1.00      1.00      1.00       840\n",
      "weighted avg       1.00      1.00      1.00       840\n",
      "\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        65\n",
      "           1       1.00      1.00      1.00       682\n",
      "           2       1.00      1.00      1.00        12\n",
      "           3       1.00      1.00      1.00        81\n",
      "\n",
      "    accuracy                           1.00       840\n",
      "   macro avg       1.00      1.00      1.00       840\n",
      "weighted avg       1.00      1.00      1.00       840\n",
      "\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        56\n",
      "           1       1.00      1.00      1.00       716\n",
      "           2       1.00      1.00      1.00         9\n",
      "           3       1.00      1.00      1.00        59\n",
      "\n",
      "    accuracy                           1.00       840\n",
      "   macro avg       1.00      1.00      1.00       840\n",
      "weighted avg       1.00      1.00      1.00       840\n",
      "\n",
      "--------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Partition 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        59\n",
      "           1       1.00      1.00      1.00       684\n",
      "           2       1.00      1.00      1.00        16\n",
      "           3       1.00      1.00      1.00        82\n",
      "\n",
      "    accuracy                           1.00       841\n",
      "   macro avg       1.00      1.00      1.00       841\n",
      "weighted avg       1.00      1.00      1.00       841\n",
      "\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        54\n",
      "           1       1.00      1.00      1.00       722\n",
      "           2       1.00      1.00      1.00         7\n",
      "           3       1.00      1.00      1.00        57\n",
      "\n",
      "    accuracy                           1.00       840\n",
      "   macro avg       1.00      1.00      1.00       840\n",
      "weighted avg       1.00      1.00      1.00       840\n",
      "\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        65\n",
      "           1       1.00      1.00      1.00       682\n",
      "           2       1.00      1.00      1.00        12\n",
      "           3       1.00      1.00      1.00        81\n",
      "\n",
      "    accuracy                           1.00       840\n",
      "   macro avg       1.00      1.00      1.00       840\n",
      "weighted avg       1.00      1.00      1.00       840\n",
      "\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        56\n",
      "           1       1.00      1.00      1.00       716\n",
      "           2       1.00      1.00      1.00         9\n",
      "           3       1.00      1.00      1.00        59\n",
      "\n",
      "    accuracy                           1.00       840\n",
      "   macro avg       1.00      1.00      1.00       840\n",
      "weighted avg       1.00      1.00      1.00       840\n",
      "\n",
      "--------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Partition 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        59\n",
      "           1       1.00      1.00      1.00       684\n",
      "           2       1.00      1.00      1.00        16\n",
      "           3       1.00      1.00      1.00        82\n",
      "\n",
      "    accuracy                           1.00       841\n",
      "   macro avg       1.00      1.00      1.00       841\n",
      "weighted avg       1.00      1.00      1.00       841\n",
      "\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        57\n",
      "           1       1.00      1.00      1.00       705\n",
      "           2       1.00      1.00      1.00         7\n",
      "           3       1.00      1.00      1.00        71\n",
      "\n",
      "    accuracy                           1.00       840\n",
      "   macro avg       1.00      1.00      1.00       840\n",
      "weighted avg       1.00      1.00      1.00       840\n",
      "\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        65\n",
      "           1       1.00      1.00      1.00       682\n",
      "           2       1.00      1.00      1.00        12\n",
      "           3       1.00      1.00      1.00        81\n",
      "\n",
      "    accuracy                           1.00       840\n",
      "   macro avg       1.00      1.00      1.00       840\n",
      "weighted avg       1.00      1.00      1.00       840\n",
      "\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        56\n",
      "           1       1.00      1.00      1.00       716\n",
      "           2       1.00      1.00      1.00         9\n",
      "           3       1.00      1.00      1.00        59\n",
      "\n",
      "    accuracy                           1.00       840\n",
      "   macro avg       1.00      1.00      1.00       840\n",
      "weighted avg       1.00      1.00      1.00       840\n",
      "\n",
      "--------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Partition 4:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        59\n",
      "           1       1.00      1.00      1.00       684\n",
      "           2       1.00      1.00      1.00        16\n",
      "           3       1.00      1.00      1.00        82\n",
      "\n",
      "    accuracy                           1.00       841\n",
      "   macro avg       1.00      1.00      1.00       841\n",
      "weighted avg       1.00      1.00      1.00       841\n",
      "\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        57\n",
      "           1       1.00      1.00      1.00       705\n",
      "           2       1.00      1.00      1.00         7\n",
      "           3       1.00      1.00      1.00        71\n",
      "\n",
      "    accuracy                           1.00       840\n",
      "   macro avg       1.00      1.00      1.00       840\n",
      "weighted avg       1.00      1.00      1.00       840\n",
      "\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        54\n",
      "           1       1.00      1.00      1.00       722\n",
      "           2       1.00      1.00      1.00         7\n",
      "           3       1.00      1.00      1.00        57\n",
      "\n",
      "    accuracy                           1.00       840\n",
      "   macro avg       1.00      1.00      1.00       840\n",
      "weighted avg       1.00      1.00      1.00       840\n",
      "\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        56\n",
      "           1       1.00      1.00      1.00       716\n",
      "           2       1.00      1.00      1.00         9\n",
      "           3       1.00      1.00      1.00        59\n",
      "\n",
      "    accuracy                           1.00       840\n",
      "   macro avg       1.00      1.00      1.00       840\n",
      "weighted avg       1.00      1.00      1.00       840\n",
      "\n",
      "--------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Partition 5:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        59\n",
      "           1       1.00      1.00      1.00       684\n",
      "           2       1.00      1.00      1.00        16\n",
      "           3       1.00      1.00      1.00        82\n",
      "\n",
      "    accuracy                           1.00       841\n",
      "   macro avg       1.00      1.00      1.00       841\n",
      "weighted avg       1.00      1.00      1.00       841\n",
      "\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        57\n",
      "           1       1.00      1.00      1.00       705\n",
      "           2       1.00      1.00      1.00         7\n",
      "           3       1.00      1.00      1.00        71\n",
      "\n",
      "    accuracy                           1.00       840\n",
      "   macro avg       1.00      1.00      1.00       840\n",
      "weighted avg       1.00      1.00      1.00       840\n",
      "\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        54\n",
      "           1       1.00      1.00      1.00       722\n",
      "           2       1.00      1.00      1.00         7\n",
      "           3       1.00      1.00      1.00        57\n",
      "\n",
      "    accuracy                           1.00       840\n",
      "   macro avg       1.00      1.00      1.00       840\n",
      "weighted avg       1.00      1.00      1.00       840\n",
      "\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        65\n",
      "           1       1.00      1.00      1.00       682\n",
      "           2       1.00      1.00      1.00        12\n",
      "           3       1.00      1.00      1.00        81\n",
      "\n",
      "    accuracy                           1.00       840\n",
      "   macro avg       1.00      1.00      1.00       840\n",
      "weighted avg       1.00      1.00      1.00       840\n",
      "\n",
      "--------------------------------------------------\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Load your dataset here\n",
    "X = np.array(X1)  # input features\n",
    "y = np.array(Y1)  # output labels\n",
    "\n",
    "# Define the number of partitions\n",
    "n_splits = 5\n",
    "\n",
    "# Shuffle the data randomly\n",
    "np.random.seed(42)\n",
    "indices = np.random.permutation(len(X))\n",
    "# print(indices)\n",
    "X = X[indices]\n",
    "y = y[indices]\n",
    "\n",
    "# Create the KFold object to generate the partitions\n",
    "kf = KFold(n_splits=n_splits)\n",
    "\n",
    "# Train and test the model on different partitions\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    print(f\"Partition {i+1}:\")\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Train the machine learning model on the training set\n",
    "    model = RandomForestRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Test the machine learning model on the remaining partitions\n",
    "    for j, (train_index2, test_index2) in enumerate(kf.split(X)):\n",
    "        if j != i:\n",
    "            X_train2, X_test2 = X[train_index2], X[test_index2]\n",
    "            y_train2, y_test2 = y[train_index2], y[test_index2]\n",
    "            \n",
    "            y_pred = model.predict(X_test2)\n",
    "            predicted_integers = [int(round(value)) for value in y_pred]\n",
    "            print(classification_report(y_test2,predicted_integers))      \n",
    "            print(\"-\"*50)\n",
    "    print('-'*55)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pass 1 with confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = pd.DataFrame(columns=['Partition','Precision','recall','F-score','FPR','Accuracy','Sensitivity','Specificity']) # creating empty data frame with some column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partition 1:\n",
      "precision: 1.0\n",
      "recall: 0.9516129032258065\n",
      "F-score: 0.9752066115702479\n",
      "FPR:0.0 \n",
      "Accuracy: 0.9959623149394348\n",
      "Sensitivity: 0.9516129032258065\n",
      "Specificity: 1.0\n",
      "-------------------------\n",
      "Partition 2:\n",
      "precision: 0.9824561403508771\n",
      "recall: 0.9655172413793104\n",
      "F-score: 0.9739130434782608\n",
      "FPR:0.0014204545454545455 \n",
      "Accuracy: 0.9960629921259843\n",
      "Sensitivity: 0.9655172413793104\n",
      "Specificity: 0.9985795454545454\n",
      "-------------------------\n",
      "Partition 3:\n",
      "precision: 1.0\n",
      "recall: 0.9818181818181818\n",
      "F-score: 0.9908256880733944\n",
      "FPR:0.0 \n",
      "Accuracy: 0.9987113402061856\n",
      "Sensitivity: 0.9818181818181818\n",
      "Specificity: 1.0\n",
      "-------------------------\n",
      "Partition 4:\n",
      "precision: 0.9692307692307692\n",
      "recall: 1.0\n",
      "F-score: 0.9843749999999999\n",
      "FPR:0.0029282576866764276 \n",
      "Accuracy: 0.9973190348525469\n",
      "Sensitivity: 1.0\n",
      "Specificity: 0.9970717423133236\n",
      "-------------------------\n",
      "Partition 5:\n",
      "precision: 0.9821428571428571\n",
      "recall: 0.9821428571428571\n",
      "F-score: 0.9821428571428571\n",
      "FPR:0.0013966480446927375 \n",
      "Accuracy: 0.9974093264248705\n",
      "Sensitivity: 0.9821428571428571\n",
      "Specificity: 0.9986033519553073\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load your dataset here\n",
    "X = np.array(X1)  # input features\n",
    "y = np.array(Y1)  # output labels\n",
    "\n",
    "# Define the number of partitions\n",
    "n_splits = 5\n",
    "\n",
    "# Shuffle the data randomly\n",
    "np.random.seed(42)\n",
    "indices = np.random.permutation(len(X))\n",
    "X = X[indices]\n",
    "y = y[indices]\n",
    "\n",
    "# Create the KFold object to generate the partitions\n",
    "kf = KFold(n_splits=n_splits)\n",
    "\n",
    "# Train and test the random forest model on each partition\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    print(f\"Partition {i+1}:\")\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Train the random forest model on the training set\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Test the random forest model on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    predicted_integers = [int(round(value)) for value in y_pred]\n",
    "\n",
    "    a = confusion_matrix(y_test,predicted_integers)\n",
    "\n",
    "    precision = a[0][0]/(a[0][0]+a[0][1])\n",
    "    recall = a[0][0]/(a[0][0]+a[1][0])\n",
    "    F_score = (2*(precision*recall))/(precision+recall)\n",
    "    Fal_ps_r = a[0][1]/(a[0][1]+a[1][1])\n",
    "    Accuracy = (a[0][0]+a[1][1])/(a[0][0]+a[0][1]+a[1][0]+a[1][1])\n",
    "    Sensitivity = a[0][0]/(a[0][0]+a[1][0])\n",
    "    Specificity = a[1][1]/(a[1][1]+a[0][1])\n",
    "\n",
    "    row = [i+1,precision,recall,F_score,Fal_ps_r,Accuracy,Sensitivity,Specificity]\n",
    "    print(f\"precision: {precision}\")\n",
    "    print(f\"recall: {recall}\")\n",
    "    print(f\"F-score: {F_score}\")\n",
    "    print(f\"FPR:{Fal_ps_r} \")\n",
    "    print(f\"Accuracy: {Accuracy}\")\n",
    "    print(f\"Sensitivity: {Sensitivity}\")\n",
    "    print(f\"Specificity: {Specificity}\")\n",
    "\n",
    "    dff.loc[len(dff)] = row \n",
    "\n",
    "    \n",
    "    print('-'*25)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pass 2 with confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame(columns=['Partition','Sub partition','Precision','recall','F-score','FPR','Accuracy','Sensitivity','Specificity']) # creating an empty Dataframe with some columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partition 1:\n",
      "precision: 1.0\n",
      "recall: 1.0\n",
      "F-score: 1.0\n",
      "FPR:0.0 \n",
      "Accuracy: 1.0\n",
      "Sensitivity: 1.0\n",
      "Specificity: 1.0\n",
      "--------------------------------------------------\n",
      "precision: 1.0\n",
      "recall: 1.0\n",
      "F-score: 1.0\n",
      "FPR:0.0 \n",
      "Accuracy: 1.0\n",
      "Sensitivity: 1.0\n",
      "Specificity: 1.0\n",
      "--------------------------------------------------\n",
      "precision: 1.0\n",
      "recall: 1.0\n",
      "F-score: 1.0\n",
      "FPR:0.0 \n",
      "Accuracy: 1.0\n",
      "Sensitivity: 1.0\n",
      "Specificity: 1.0\n",
      "--------------------------------------------------\n",
      "precision: 1.0\n",
      "recall: 1.0\n",
      "F-score: 1.0\n",
      "FPR:0.0 \n",
      "Accuracy: 1.0\n",
      "Sensitivity: 1.0\n",
      "Specificity: 1.0\n",
      "--------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Partition 2:\n",
      "precision: 1.0\n",
      "recall: 1.0\n",
      "F-score: 1.0\n",
      "FPR:0.0 \n",
      "Accuracy: 1.0\n",
      "Sensitivity: 1.0\n",
      "Specificity: 1.0\n",
      "--------------------------------------------------\n",
      "precision: 1.0\n",
      "recall: 1.0\n",
      "F-score: 1.0\n",
      "FPR:0.0 \n",
      "Accuracy: 1.0\n",
      "Sensitivity: 1.0\n",
      "Specificity: 1.0\n",
      "--------------------------------------------------\n",
      "precision: 1.0\n",
      "recall: 1.0\n",
      "F-score: 1.0\n",
      "FPR:0.0 \n",
      "Accuracy: 1.0\n",
      "Sensitivity: 1.0\n",
      "Specificity: 1.0\n",
      "--------------------------------------------------\n",
      "precision: 1.0\n",
      "recall: 1.0\n",
      "F-score: 1.0\n",
      "FPR:0.0 \n",
      "Accuracy: 1.0\n",
      "Sensitivity: 1.0\n",
      "Specificity: 1.0\n",
      "--------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Partition 3:\n",
      "precision: 1.0\n",
      "recall: 1.0\n",
      "F-score: 1.0\n",
      "FPR:0.0 \n",
      "Accuracy: 1.0\n",
      "Sensitivity: 1.0\n",
      "Specificity: 1.0\n",
      "--------------------------------------------------\n",
      "precision: 1.0\n",
      "recall: 1.0\n",
      "F-score: 1.0\n",
      "FPR:0.0 \n",
      "Accuracy: 1.0\n",
      "Sensitivity: 1.0\n",
      "Specificity: 1.0\n",
      "--------------------------------------------------\n",
      "precision: 1.0\n",
      "recall: 1.0\n",
      "F-score: 1.0\n",
      "FPR:0.0 \n",
      "Accuracy: 1.0\n",
      "Sensitivity: 1.0\n",
      "Specificity: 1.0\n",
      "--------------------------------------------------\n",
      "precision: 1.0\n",
      "recall: 1.0\n",
      "F-score: 1.0\n",
      "FPR:0.0 \n",
      "Accuracy: 1.0\n",
      "Sensitivity: 1.0\n",
      "Specificity: 1.0\n",
      "--------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Partition 4:\n",
      "precision: 1.0\n",
      "recall: 1.0\n",
      "F-score: 1.0\n",
      "FPR:0.0 \n",
      "Accuracy: 1.0\n",
      "Sensitivity: 1.0\n",
      "Specificity: 1.0\n",
      "--------------------------------------------------\n",
      "precision: 1.0\n",
      "recall: 1.0\n",
      "F-score: 1.0\n",
      "FPR:0.0 \n",
      "Accuracy: 1.0\n",
      "Sensitivity: 1.0\n",
      "Specificity: 1.0\n",
      "--------------------------------------------------\n",
      "precision: 1.0\n",
      "recall: 1.0\n",
      "F-score: 1.0\n",
      "FPR:0.0 \n",
      "Accuracy: 1.0\n",
      "Sensitivity: 1.0\n",
      "Specificity: 1.0\n",
      "--------------------------------------------------\n",
      "precision: 1.0\n",
      "recall: 1.0\n",
      "F-score: 1.0\n",
      "FPR:0.0 \n",
      "Accuracy: 1.0\n",
      "Sensitivity: 1.0\n",
      "Specificity: 1.0\n",
      "--------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "Partition 5:\n",
      "precision: 1.0\n",
      "recall: 1.0\n",
      "F-score: 1.0\n",
      "FPR:0.0 \n",
      "Accuracy: 1.0\n",
      "Sensitivity: 1.0\n",
      "Specificity: 1.0\n",
      "--------------------------------------------------\n",
      "precision: 1.0\n",
      "recall: 1.0\n",
      "F-score: 1.0\n",
      "FPR:0.0 \n",
      "Accuracy: 1.0\n",
      "Sensitivity: 1.0\n",
      "Specificity: 1.0\n",
      "--------------------------------------------------\n",
      "precision: 1.0\n",
      "recall: 1.0\n",
      "F-score: 1.0\n",
      "FPR:0.0 \n",
      "Accuracy: 1.0\n",
      "Sensitivity: 1.0\n",
      "Specificity: 1.0\n",
      "--------------------------------------------------\n",
      "precision: 1.0\n",
      "recall: 1.0\n",
      "F-score: 1.0\n",
      "FPR:0.0 \n",
      "Accuracy: 1.0\n",
      "Sensitivity: 1.0\n",
      "Specificity: 1.0\n",
      "--------------------------------------------------\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load your dataset here\n",
    "X = np.array(X1)  # input features\n",
    "y = np.array(Y1)  # output labels\n",
    "\n",
    "# Define the number of partitions\n",
    "n_splits = 5\n",
    "\n",
    "# Shuffle the data randomly\n",
    "np.random.seed(42)\n",
    "indices = np.random.permutation(len(X))\n",
    "# print(indices)\n",
    "X = X[indices]\n",
    "y = y[indices]\n",
    "\n",
    "# Create the KFold object to generate the partitions\n",
    "kf = KFold(n_splits=n_splits)\n",
    "\n",
    "# Train and test the model on different partitions\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    print(f\"Partition {i+1}:\")\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Train the machine learning model on the training set\n",
    "    model = RandomForestRegressor(n_estimators=200, random_state=20)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Test the machine learning model on the remaining partitions\n",
    "    for j, (train_index2, test_index2) in enumerate(kf.split(X)):\n",
    "        if j != i:\n",
    "            X_train2, X_test2 = X[train_index2], X[test_index2]\n",
    "            y_train2, y_test2 = y[train_index2], y[test_index2]\n",
    "            \n",
    "            y_pred = model.predict(X_test2)\n",
    "            predicted_integers = [int(round(value)) for value in y_pred]\n",
    "            a = confusion_matrix(y_test2,predicted_integers)\n",
    "\n",
    "            \n",
    "            precision = a[0][0]/(a[0][0]+a[0][1])\n",
    "            recall = a[0][0]/(a[0][0]+a[1][0])\n",
    "            F_score = (2*(precision*recall))/(precision+recall)\n",
    "            Fal_ps_r = a[0][1]/(a[0][1]+a[1][1])\n",
    "            Accuracy = (a[0][0]+a[1][1])/(a[0][0]+a[0][1]+a[1][0]+a[1][1])\n",
    "            Sensitivity = a[0][0]/(a[0][0]+a[1][0])\n",
    "            Specificity = a[1][1]/(a[1][1]+a[0][1]) \n",
    "\n",
    "            print(f\"precision: {precision}\")\n",
    "            print(f\"recall: {recall}\")\n",
    "            print(f\"F-score: {F_score}\")\n",
    "            print(f\"FPR:{Fal_ps_r} \")\n",
    "            print(f\"Accuracy: {Accuracy}\")\n",
    "            print(f\"Sensitivity: {Sensitivity}\")\n",
    "            print(f\"Specificity: {Specificity}\") \n",
    "            row = [i+1,j+1,precision,recall,F_score,Fal_ps_r,Accuracy,Sensitivity,Specificity]\n",
    "            df3.loc[len(df3)] = row # inserting evaluation data in a dataframe\n",
    "            print(\"-\"*50)\n",
    "    print('-'*55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Partition</th>\n",
       "      <th>Precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F-score</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.951613</td>\n",
       "      <td>0.975207</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.995962</td>\n",
       "      <td>0.951613</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.982456</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.973913</td>\n",
       "      <td>0.001420</td>\n",
       "      <td>0.996063</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.998580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981818</td>\n",
       "      <td>0.990826</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.998711</td>\n",
       "      <td>0.981818</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.969231</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.002928</td>\n",
       "      <td>0.997319</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.001397</td>\n",
       "      <td>0.997409</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.998603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Partition  Precision    recall   F-score       FPR  Accuracy  Sensitivity  \\\n",
       "0        1.0   1.000000  0.951613  0.975207  0.000000  0.995962     0.951613   \n",
       "1        2.0   0.982456  0.965517  0.973913  0.001420  0.996063     0.965517   \n",
       "2        3.0   1.000000  0.981818  0.990826  0.000000  0.998711     0.981818   \n",
       "3        4.0   0.969231  1.000000  0.984375  0.002928  0.997319     1.000000   \n",
       "4        5.0   0.982143  0.982143  0.982143  0.001397  0.997409     0.982143   \n",
       "\n",
       "   Specificity  \n",
       "0     1.000000  \n",
       "1     0.998580  \n",
       "2     1.000000  \n",
       "3     0.997072  \n",
       "4     0.998603  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Partition</th>\n",
       "      <th>Sub partition</th>\n",
       "      <th>Precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F-score</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Partition  Sub partition  Precision  recall  F-score  FPR  Accuracy  \\\n",
       "0         1.0            2.0        1.0     1.0      1.0  0.0       1.0   \n",
       "1         1.0            3.0        1.0     1.0      1.0  0.0       1.0   \n",
       "2         1.0            4.0        1.0     1.0      1.0  0.0       1.0   \n",
       "3         1.0            5.0        1.0     1.0      1.0  0.0       1.0   \n",
       "4         2.0            1.0        1.0     1.0      1.0  0.0       1.0   \n",
       "5         2.0            3.0        1.0     1.0      1.0  0.0       1.0   \n",
       "6         2.0            4.0        1.0     1.0      1.0  0.0       1.0   \n",
       "7         2.0            5.0        1.0     1.0      1.0  0.0       1.0   \n",
       "8         3.0            1.0        1.0     1.0      1.0  0.0       1.0   \n",
       "9         3.0            2.0        1.0     1.0      1.0  0.0       1.0   \n",
       "10        3.0            4.0        1.0     1.0      1.0  0.0       1.0   \n",
       "11        3.0            5.0        1.0     1.0      1.0  0.0       1.0   \n",
       "12        4.0            1.0        1.0     1.0      1.0  0.0       1.0   \n",
       "13        4.0            2.0        1.0     1.0      1.0  0.0       1.0   \n",
       "14        4.0            3.0        1.0     1.0      1.0  0.0       1.0   \n",
       "15        4.0            5.0        1.0     1.0      1.0  0.0       1.0   \n",
       "16        5.0            1.0        1.0     1.0      1.0  0.0       1.0   \n",
       "17        5.0            2.0        1.0     1.0      1.0  0.0       1.0   \n",
       "18        5.0            3.0        1.0     1.0      1.0  0.0       1.0   \n",
       "19        5.0            4.0        1.0     1.0      1.0  0.0       1.0   \n",
       "\n",
       "    Sensitivity  Specificity  \n",
       "0           1.0          1.0  \n",
       "1           1.0          1.0  \n",
       "2           1.0          1.0  \n",
       "3           1.0          1.0  \n",
       "4           1.0          1.0  \n",
       "5           1.0          1.0  \n",
       "6           1.0          1.0  \n",
       "7           1.0          1.0  \n",
       "8           1.0          1.0  \n",
       "9           1.0          1.0  \n",
       "10          1.0          1.0  \n",
       "11          1.0          1.0  \n",
       "12          1.0          1.0  \n",
       "13          1.0          1.0  \n",
       "14          1.0          1.0  \n",
       "15          1.0          1.0  \n",
       "16          1.0          1.0  \n",
       "17          1.0          1.0  \n",
       "18          1.0          1.0  \n",
       "19          1.0          1.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training whole combined dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X1,Y1,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestRegressor(n_estimators=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_estimators=200)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=200)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(n_estimators=200)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = rfc.predict(X_test)\n",
    "predicted_integers = [int(round(value)) for value in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95        64\n",
      "           1       1.00      1.00      1.00       701\n",
      "           2       1.00      1.00      1.00        12\n",
      "           3       1.00      1.00      1.00        64\n",
      "\n",
      "    accuracy                           0.99       841\n",
      "   macro avg       0.99      0.99      0.99       841\n",
      "weighted avg       0.99      0.99      0.99       841\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test,predicted_integers))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
